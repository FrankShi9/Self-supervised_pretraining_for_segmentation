{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import subprocess\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models import vit_b_16\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom imports assuming they are in the parent directory\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "from data_utils import ContDataset, Transform\n",
    "from models import Decoder, MaskedAutoEncoder\n",
    "from losses import contrastive_loss, dice_loss\n",
    "from metrics import pixel_wise_accuracy, evaluate_model_performance\n",
    "from data_augmentation import DataAugmentation\n",
    "from utils import test_visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for datasets\n",
    "batch_size = 64\n",
    "dataset_config = {\n",
    "    'image_size': (224, 224),\n",
    "    'data_path': '../datasets/data',\n",
    "    'flowers_data_path': '../datasets/102flowers',\n",
    "    'aug_data_path': '../datasets/aug_data'\n",
    "}\n",
    "\n",
    "pre_train = {\n",
    "    'num_samples': 100, # Size of the pre-trained dataset\n",
    "    'epochs': 10,  # Total epochs for pre-training\n",
    "    'learning_rate': 1e-3 # Learning rate in the pre-training phase\n",
    "}\n",
    "\n",
    "# Split configurations for fine-tuning\n",
    "fine_tune_dataset_split = {\n",
    "    'use_data_ratio': 1.0, # Fine-tuning the use ratio of the dataset\n",
    "    'train_ratio': 0.8,  # Fine-tuning the scale of the training dataset\n",
    "    'test_ratio': 0.2, #Fine-tuning the scale of the test dataset\n",
    "}\n",
    "\n",
    "# Training configuration for fine-tuning\n",
    "fine_tune_training_config = {\n",
    "    'batch_size': 64, \n",
    "    'shuffle_train': True,  \n",
    "    'shuffle_test': False,\n",
    "    'training_epochs' : 20, # Fine-tuning phase training epochs\n",
    "    'learning_rate': 1e-4 # Learning rate in the pre-training phase\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rB-YQA14Crl"
   },
   "source": [
    "# Pre-Train and Fine-tuning of pre-trained models （Use of pet-related pre-training data）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "U8g9l54R_pWH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data folder already exists, no need to unzip it again\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 6269/10000 [01:15<00:46, 80.49it/s] Corrupt JPEG data: 254 extraneous bytes before marker 0xd9\n",
      " 77%|███████▋  | 7697/10000 [01:32<00:36, 62.76it/s] Corrupt JPEG data: 2230 extraneous bytes before marker 0xd9\n",
      "100%|██████████| 10000/10000 [02:00<00:00, 82.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in data directory: 48062\n",
      "Number of files in aug_data directory - Pre-training dataset: 20000\n"
     ]
    }
   ],
   "source": [
    "# Unzip dataset if not already present\n",
    "if not os.path.exists(dataset_config['data_path']):\n",
    "    subprocess.run(f'unzip ../datasets/data.zip -d {\"../datasets\"}', \n",
    "                   shell=True, stdout=subprocess.DEVNULL, \n",
    "                   stderr=subprocess.DEVNULL)\n",
    "else:\n",
    "    print(\"The data folder already exists, no need to unzip it again\")\n",
    "\n",
    "# Initialize data augmentation module\n",
    "augmentor = DataAugmentation(dataset_config['data_path'], \n",
    "                             dataset_config['aug_data_path'], \n",
    "                             pre_train['num_samples'])\n",
    "augmentor.augment_images()\n",
    "\n",
    "# List files and count them in each directory using subprocess\n",
    "data_files_count = subprocess.check_output(f'ls -1 {dataset_config[\"data_path\"]} | wc -l', shell=True).strip().decode()\n",
    "aug_data_files_count = subprocess.check_output(f'ls -1 {dataset_config[\"aug_data_path\"]} | wc -l', shell=True).strip().decode()\n",
    "print(f\"Number of files in data directory: {data_files_count}\")\n",
    "print(f\"Number of files in aug_data directory - Pre-training dataset: {aug_data_files_count}\")\n",
    "\n",
    "# Define a transform to convert the images to PyTorch tensors and any other desired transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(dataset_config['image_size']),  # Resize the image to 224x224 pixels.\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor.\n",
    "])\n",
    "\n",
    "# Load dataset and create dataloader\n",
    "dataset = ContDataset(folder_path=dataset_config['aug_data_path'], \n",
    "                      folder_path1=dataset_config['data_path'], \n",
    "                      transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size , shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Setup model and training devices\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = vit_b_16(pretrained=False).to(device)\n",
    "decoder = Decoder(1000, 512, 3 * 224 * 224).to(device)\n",
    "pre_model_related_pets = MaskedAutoEncoder(encoder, decoder).to(device)\n",
    "optimizer = optim.Adam(pre_model_related_pets.parameters(), lr=pre_train['learning_rate'])\n",
    "mask = torch.rand(size=(1, 3, 224, 224)) > 0.5\n",
    "mask = mask.to(device)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the pre-training phase...\n",
      "Epoch 1, Avg. Loss: 19.749, Duration: 253.78 seconds\n",
      "Epoch 2, Avg. Loss: 15.358, Duration: 251.13 seconds\n",
      "Epoch 3, Avg. Loss: 15.322, Duration: 250.60 seconds\n",
      "Epoch 4, Avg. Loss: 15.270, Duration: 250.36 seconds\n",
      "Epoch 5, Avg. Loss: 15.246, Duration: 249.89 seconds\n",
      "Epoch 6, Avg. Loss: 15.230, Duration: 249.78 seconds\n",
      "Epoch 7, Avg. Loss: 15.216, Duration: 249.79 seconds\n",
      "Epoch 8, Avg. Loss: 15.213, Duration: 250.59 seconds\n",
      "Epoch 9, Avg. Loss: 15.208, Duration: 249.92 seconds\n",
      "Epoch 10, Avg. Loss: 15.212, Duration: 249.80 seconds\n",
      "Pre-training phase completed.\n"
     ]
    }
   ],
   "source": [
    "# Start the pre-training phase\n",
    "print(\"Starting the pre-training related pets phase...\")\n",
    "\n",
    "for epoch in range(pre_train['epochs']):\n",
    "    start_time = time.time()\n",
    "    pre_model_related_pets.train()\n",
    "    epoch_losses = []  # Collect losses for each batch to calculate epoch average\n",
    "\n",
    "    for x, z1, z2 in dataloader:\n",
    "        inputs, x1, x2 = x.to(\"cuda\"), z1.to(\"cuda\"), z2.to(\"cuda\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            try:\n",
    "                p1, p2 = pre_model_related_pets(x1, mask).reshape(64,3,224,224), pre_model_related_pets(x2, mask).reshape(64,3,224,224)\n",
    "                loss = contrastive_loss(inputs, p1, p2)\n",
    "                epoch_losses.append(loss.item())\n",
    "\n",
    "            except Exception as e:\n",
    "                continue  # Skip the backward pass and optimizer step if an error occurred\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "    # Calculate and print the average loss for the epoch\n",
    "    epoch_avg_loss = sum(epoch_losses) / len(epoch_losses) if epoch_losses else float('inf')\n",
    "    end_time = time.time()\n",
    "    epoch_duration = end_time - start_time\n",
    "    print(f'Epoch {epoch+1}, Avg. Loss: {epoch_avg_loss:.3f}, Duration: {epoch_duration:.2f} seconds')\n",
    "\n",
    "print(\"Pre-training related pets phase completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cn2OQTGMCTkL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Original dataset size: 3680\n",
      "Fine-tuning Used dataset size: 3680 (100.0%)\n",
      "Fine-tuning Training dataset size: 2944\n",
      "Fine-tuning Testing dataset size: 736\n"
     ]
    }
   ],
   "source": [
    "transform = Transform(image_size = dataset_config['image_size'])\n",
    "full_dataset = torchvision.datasets.OxfordIIITPet(root='../datasets',\n",
    "                        target_types='segmentation',\n",
    "                        transforms=transform,\n",
    "                        download=True)\n",
    "\n",
    "\n",
    "# Define the size of training and testing datasets\n",
    "total_size = len(full_dataset)\n",
    "used_data_size = int(total_size * fine_tune_dataset_split['use_data_ratio'])\n",
    "train_size = int(used_data_size * fine_tune_dataset_split['train_ratio'])\n",
    "test_size = used_data_size - train_size\n",
    "\n",
    "# Split the dataset\n",
    "indices = torch.randperm(total_size).tolist()\n",
    "used_indices = indices[:used_data_size]\n",
    "train_indices = used_indices[:train_size]\n",
    "test_indices = used_indices[train_size:]\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(full_dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(full_dataset, test_indices)\n",
    "\n",
    "\n",
    "print(f\"Fine-tuning Original dataset size: {total_size}\")\n",
    "print(f\"Fine-tuning Used dataset size: {used_data_size} ({fine_tune_dataset_split['use_data_ratio']*100}%)\")\n",
    "print(f\"Fine-tuning Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Fine-tuning Testing dataset size: {len(test_dataset)}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=fine_tune_training_config['batch_size'], shuffle=fine_tune_training_config['shuffle_train'], drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=fine_tune_training_config['shuffle_test'], drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the pre-trained model on the fine-tuning test dataset: 0.35\n",
      "IoU score of the pre-trained model on the fine-tuning test dataset: 0.18\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_performance(pre_model_related_pets, test_loader, device, mask, \"the pre-trained related pets model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the fine-tuning process with the pre-trained model...\n",
      "Epoch 1, Loss: 0.495, Accuracy: 0.640, Duration: 18.90 seconds\n",
      "Epoch 2, Loss: 0.472, Accuracy: 0.664, Duration: 18.65 seconds\n",
      "Epoch 3, Loss: 0.474, Accuracy: 0.658, Duration: 18.59 seconds\n",
      "Epoch 4, Loss: 0.485, Accuracy: 0.644, Duration: 18.59 seconds\n",
      "Epoch 5, Loss: 0.472, Accuracy: 0.646, Duration: 18.61 seconds\n",
      "Epoch 6, Loss: 0.497, Accuracy: 0.635, Duration: 18.72 seconds\n",
      "Epoch 7, Loss: 0.479, Accuracy: 0.649, Duration: 18.74 seconds\n",
      "Epoch 8, Loss: 0.505, Accuracy: 0.630, Duration: 18.60 seconds\n",
      "Epoch 9, Loss: 0.487, Accuracy: 0.641, Duration: 18.60 seconds\n",
      "Epoch 10, Loss: 0.489, Accuracy: 0.641, Duration: 18.64 seconds\n",
      "Epoch 11, Loss: 0.478, Accuracy: 0.645, Duration: 18.62 seconds\n",
      "Epoch 12, Loss: 0.471, Accuracy: 0.659, Duration: 18.55 seconds\n",
      "Epoch 13, Loss: 0.491, Accuracy: 0.640, Duration: 18.65 seconds\n",
      "Epoch 14, Loss: 0.495, Accuracy: 0.637, Duration: 18.62 seconds\n",
      "Epoch 15, Loss: 0.486, Accuracy: 0.647, Duration: 18.61 seconds\n",
      "Epoch 16, Loss: 0.480, Accuracy: 0.645, Duration: 18.62 seconds\n",
      "Epoch 17, Loss: 0.474, Accuracy: 0.643, Duration: 18.59 seconds\n",
      "Epoch 18, Loss: 0.473, Accuracy: 0.648, Duration: 18.57 seconds\n",
      "Epoch 19, Loss: 0.483, Accuracy: 0.653, Duration: 18.51 seconds\n",
      "Epoch 20, Loss: 0.488, Accuracy: 0.643, Duration: 18.60 seconds\n",
      "Fine-tuning completed.\n"
     ]
    }
   ],
   "source": [
    "# Initialize mask and model for fine-tuning\n",
    "mask = torch.ones(size=(1, 3, 224, 224)).to(device)\n",
    "fine_model_with_pre_related_pets = pre_model_related_pets.to(device)\n",
    "optimizer = optim.Adam(fine_model_with_pre_related_pets.parameters(), lr=fine_tune_training_config['learning_rate'])\n",
    "\n",
    "# Start the fine-tuning process\n",
    "print(\"Starting the fine-tuning process with the pre-trained related pets model...\")\n",
    "\n",
    "for epoch in range(fine_tune_training_config['training_epochs']):\n",
    "    start_time = time.time()\n",
    "    fine_model_with_pre_related_pets.train()  # Ensure the model is in training mode\n",
    "    for x, y in train_loader:\n",
    "        inputs, targets = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Generate predictions using the fine-tuned model\n",
    "        preds = fine_model_with_pre_related_pets(inputs, mask)\n",
    "        if preds.size(0) == inputs.size(0):\n",
    "            batch_size = preds.shape[0]\n",
    "            preds = preds.reshape(batch_size, 3, 224, 224)\n",
    "    \n",
    "            # Compute the loss and accuracy\n",
    "            loss = dice_loss(preds, targets)\n",
    "            accuracy = pixel_wise_accuracy(preds, targets)\n",
    "    \n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    end_time = time.time()\n",
    "    epoch_duration = end_time - start_time\n",
    "\n",
    "    # Print epoch results\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item():.3f}, Accuracy: {accuracy:.3f}, Duration: {epoch_duration:.2f} seconds')\n",
    "\n",
    "print(\"Fine-tuning completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the fine-tuned model on the fine-tuning test dataset: 0.64\n",
      "IoU score of the fine-tuned model on the fine-tuning test dataset: 0.39\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_performance(fine_model_with_pre_related_pets, test_loader, device, mask, \"The fine-tuned model based on pre-trained with related pets model\")\n",
    "\n",
    "test_visualization(fine_model_with_pre_related_pets, test_loader, mask, device, f\"The fine-tuned model based on pre-trained with related pets model\", \"../images\")\n",
    "\n",
    "# Freeing up graphics card memory\n",
    "fine_model_with_pre_related_pets.to('cpu')\n",
    "torch.cuda.empty_cache()  \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Train and Fine-tuning of pre-trained models （Use of pre-training data not related to pets）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip dataset if not already present\n",
    "if not os.path.exists(dataset_config['flowers_data_path']):\n",
    "    subprocess.run(f'unzip ../datasets/102flowers.zip -d {\"../datasets\"}', \n",
    "                   shell=True, stdout=subprocess.DEVNULL, \n",
    "                   stderr=subprocess.DEVNULL)\n",
    "else:\n",
    "    print(\"The data folder already exists, no need to unzip it again\")\n",
    "\n",
    "# Initialize data augmentation module\n",
    "augmentor = DataAugmentation(dataset_config['flowers_data_path'], \n",
    "                             dataset_config['aug_data_path'], \n",
    "                             pre_train['num_samples'])\n",
    "augmentor.augment_images()\n",
    "\n",
    "# List files and count them in each directory using subprocess\n",
    "data_files_count = subprocess.check_output(f'ls -1 {dataset_config[\"data_path\"]} | wc -l', shell=True).strip().decode()\n",
    "aug_data_files_count = subprocess.check_output(f'ls -1 {dataset_config[\"aug_data_path\"]} | wc -l', shell=True).strip().decode()\n",
    "print(f\"Number of files in data directory: {data_files_count}\")\n",
    "print(f\"Number of files in aug_data directory - Pre-training dataset: {aug_data_files_count}\")\n",
    "\n",
    "# Define a transform to convert the images to PyTorch tensors and any other desired transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(dataset_config['image_size']),  # Resize the image to 224x224 pixels.\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor.\n",
    "])\n",
    "\n",
    "# Load dataset and create dataloader\n",
    "dataset = ContDataset(folder_path=dataset_config['aug_data_path'], \n",
    "                      folder_path1=dataset_config['flowers_data_path'], \n",
    "                      transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size , shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model and training devices\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = vit_b_16(pretrained=False).to(device)\n",
    "decoder = Decoder(1000, 512, 3 * 224 * 224).to(device)\n",
    "pre_model_not_related_pets = MaskedAutoEncoder(encoder, decoder).to(device)\n",
    "optimizer = optim.Adam(pre_model_not_related_pets.parameters(), lr=pre_train['learning_rate'])\n",
    "mask = torch.rand(size=(1, 3, 224, 224)) > 0.5\n",
    "mask = mask.to(device)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the pre-training phase\n",
    "print(\"Starting the pre-training not related pets phase...\")\n",
    "\n",
    "for epoch in range(pre_train['epochs']):\n",
    "    start_time = time.time()\n",
    "    pre_model_not_related_pets.train()\n",
    "    epoch_losses = []  # Collect losses for each batch to calculate epoch average\n",
    "\n",
    "    for x, z1, z2 in dataloader:\n",
    "        inputs, x1, x2 = x.to(\"cuda\"), z1.to(\"cuda\"), z2.to(\"cuda\")\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            try:\n",
    "                p1, p2 = pre_model_not_related_pets(x1, mask).reshape(64,3,224,224), pre_model_not_related_pets(x2, mask).reshape(64,3,224,224)\n",
    "                loss = contrastive_loss(inputs, p1, p2)\n",
    "                epoch_losses.append(loss.item())\n",
    "\n",
    "            except Exception as e:\n",
    "                continue  # Skip the backward pass and optimizer step if an error occurred\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "    # Calculate and print the average loss for the epoch\n",
    "    epoch_avg_loss = sum(epoch_losses) / len(epoch_losses) if epoch_losses else float('inf')\n",
    "    end_time = time.time()\n",
    "    epoch_duration = end_time - start_time\n",
    "    print(f'Epoch {epoch+1}, Avg. Loss: {epoch_avg_loss:.3f}, Duration: {epoch_duration:.2f} seconds')\n",
    "\n",
    "print(\"Pre-training not related pets phase completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_performance(pre_model_not_related_pets, test_loader, device, mask, \"the pre-trained not related pets model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize mask and model for fine-tuning\n",
    "mask = torch.ones(size=(1, 3, 224, 224)).to(device)\n",
    "fine_model_with_pre_not_related_pets = pre_model_not_related_pets.to(device)\n",
    "optimizer = optim.Adam(fine_model_with_pre_not_related_pets.parameters(), lr=fine_tune_training_config['learning_rate'])\n",
    "\n",
    "# Start the fine-tuning process\n",
    "print(\"Starting the fine-tuning process with the pre-trained not related pets model...\")\n",
    "\n",
    "for epoch in range(fine_tune_training_config['training_epochs']):\n",
    "    start_time = time.time()\n",
    "    fine_model_with_pre_not_related_pets.train()  # Ensure the model is in training mode\n",
    "    for x, y in train_loader:\n",
    "        inputs, targets = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Generate predictions using the fine-tuned model\n",
    "        preds = fine_model_with_pre_not_related_pets(inputs, mask)\n",
    "        if preds.size(0) == inputs.size(0):\n",
    "            batch_size = preds.shape[0]\n",
    "            preds = preds.reshape(batch_size, 3, 224, 224)\n",
    "    \n",
    "            # Compute the loss and accuracy\n",
    "            loss = dice_loss(preds, targets)\n",
    "            accuracy = pixel_wise_accuracy(preds, targets)\n",
    "    \n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "    end_time = time.time()\n",
    "    epoch_duration = end_time - start_time\n",
    "\n",
    "    # Print epoch results\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item():.3f}, Accuracy: {accuracy:.3f}, Duration: {epoch_duration:.2f} seconds')\n",
    "\n",
    "print(\"Fine-tuning completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_performance(fine_model_with_pre_not_related_pets, test_loader, device, mask, \"The fine-tuned model based on pre-trained with not related pets model\")\n",
    "\n",
    "test_visualization(fine_model_with_pre_not_related_pets, test_loader, mask, device, f\"The fine-tuned model based on pre-trained with not related pets model\", \"../images\")\n",
    "\n",
    "# Freeing up graphics card memory\n",
    "fine_model_with_pre_not_related_pets.to('cpu')\n",
    "torch.cuda.empty_cache()  \n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "nS825KFv5gBg",
    "yKkoSyXWviHP",
    "y2dO7EFDPOIf",
    "AzKo7ofKDKsT",
    "XmMMTxHdDISz",
    "4iw44jng77Zr",
    "0T7wuo93x5Cf",
    "S98Blxrkxv10",
    "jyzuu0tkxt0g",
    "EqeGreLbCPYO",
    "r0fzfw7LAxkd"
   ],
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
